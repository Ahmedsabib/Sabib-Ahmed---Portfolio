<!DOCTYPE html>
<html>
    <head>
        <title>Sabib Ahmed</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- UIkit CSS -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/css/uikit.min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
        <link rel="stylesheet" href="style.css">
        <!-- UIkit JS -->
        <script src="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/js/uikit.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/js/uikit-icons.min.js"></script>
    </head>
    <body>
        <nav class="uk-navbar-container uk-margin uk-light" uk-navbar>
            <div class="uk-navbar-left">
                <a class="uk-navbar-item uk-logo uk-text-primary" href="index.html">Sabib Ahmed</a>
            </div>
            <div class="uk-navbar-right">
                <ul class="uk-navbar-nav">
                    <li class="uk-active uk-visible@m"> <a href="index.html"> Home </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#about"> About </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#education"> Education </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#research"> Publications </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#thesis"> Thesis </a> </li>
                    <!-- <li class="uk-active uk-visible@m"> <a href="index.html#experience"> Experience </a> </li> -->
                    <li class="uk-active uk-visible@m"> <a href="index.html#projects"> Projects </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#skills"> Skills </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#contact"> Contact </a> </li>
                    <a class="uk-active uk-navbar-toggle uk-hidden@m" uk-navbar-toggle-icon href="#offcanvas-nav-primary" uk-toggle></a>
                </ul>
            </div>
        </nav>

        <div id="offcanvas-nav-primary" uk-offcanvas="overlay: true">
            <div class="uk-offcanvas-bar uk-flex uk-flex-column">
                <ul class="uk-nav uk-nav-primary uk-nav-center uk-margin-auto-vertical">
                    <li class="uk-active"> <a href="index.html"> Home </a> </li>
                    <li class="uk-active"> <a href="index.html#about"> About </a> </li>
                    <li class="uk-active"> <a href="index.html#education"> Education </a> </li>
                    <li class="uk-active"> <a href="index.html#research"> Publications </a> </li>
                    <li class="uk-active"> <a href="index.html#thesis"> Thesis </a> </li>
                    <!-- <li class="uk-active"> <a href="index.html#experience"> Experience </a> </li> -->
                    <li class="uk-active"> <a href="index.html#projects"> Projects </a> </li>
                    <li class="uk-active"> <a href="index.html#skills"> Skills </a> </li>
                    <li class="uk-active"> <a href="index.html#contact"> Contact </a> </li>
                </ul>
            </div>
        </div>

        <!-- Header -->
        <div class="uk-flex uk-flex-center">
            <div class="uk-container uk-width-1-1 uk-width-3-4@m uk-padding-small" uk-grid>
                <a class="uk-flex uk-flex-center uk-width-1-1 uk-width-auto@m" href="#">
                    <div class="uk-width-1-2 uk-width-medium@s uk-visible@l">
                        <img class="uk-border-circle uk-responsive-height uk-responsive-width" src="My Photo - Edited.jpg" alt="Portrait" /> </br>
                        <!-- SOCIAL ICONS -->
                        <div class="uk-flex uk-flex-center uk-margin-small-top">
                            <a href="mailto:sabibahmed40@gmail.com" class="uk-margin-small-right" aria-label="Email">
                                <i class="fas fa-envelope"></i>
                            </a>
                            <a href="https://scholar.google.com/citations?user=kb5sqbIAAAAJ&hl=en" class="uk-margin-small-right" aria-label="Google Scholar" target="_blank">
                                <i class="fas fa-graduation-cap"></i>
                            </a>
                            <a href="https://github.com/Ahmedsabib" class="uk-margin-small-right" aria-label="GitHub" target="_blank">
                                <i class="fab fa-github"></i>
                            </a>
                            <a href="https://www.linkedin.com/in/sabib-ahmed-147471251/" class="uk-margin-small-right" aria-label="LinkedIn" target="_blank">
                                <i class="fab fa-linkedin-in"></i>
                            </a>
                        </div> 
                    </div>
                </a>

                <div class="uk-width-expand uk-margin-remove">
                    <p id="about"> I am <b>Sabib Ahmed</b>, a Computer Science graduate from 
                    <a href="https://www.sec.ac.bd/" style="color:#007fe6" target='_'>Sylhet Engineering College</a> (affiliated with SUST, Bangladesh). 
                    You can reach me at <span style="color:#007fe6;">sabibahmed40@gmail.com</span>.
                    </p>
                    <p>I am seeking Ph.D. opportunities to advance <strong> interpretable, robust, and data-efficient AI</strong>, with a focus on <strong> imaging, generative models, and real-time visual detection systems</strong>. My goal is to develop deployable deep learning frameworks that integrate <strong>transformer-based architectures, diffusion and generative models, explainability, and multimodal learning </strong> for clinically and societally impactful applications.</p>
                    <p>I am <strong>seeking Ph.D. opportunities</strong> to advance AI research in medical imaging, autonomous detection, and interpretable deep learning, while contributing to impactful applications. I am particularly motivated to explore emerging research directions and translate them into practical, reliable AI systems.</p>
                    <p style="color:#fc2403"> <b> ðŸ“£ðŸ“£ðŸ“£ I am actively seeking Ph.D. opportunities for Spring 2027/Fall 2027.</b></p>
                </div>
            </div>
        </div>

        <!-- Body -->
        <div class="uk-flex uk-flex-center uk-margin-remove-top uk-margin-medium-bottom">
        <div class="uk-container uk-width-1-1 uk-width-3-4@m uk-padding-small">

            <!-- Education Section -->
            <hr class="uk-margin-small">
            <p id="education" class="uk-h2 uk-text-bold" style="color:#BF5700;">Education</p>
            <ul class="uk-list uk-list-bullet">
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>2020 â€“ 2025</strong></div>
                    <div>
                        <strong>B.Sc. in Computer Science & Engineering</strong><br>
                        Sylhet Engineering College (Affiliated with Shahjalal University of Science and Technology)<br>
                        CGPA: 3.58/4.0
                    </div>
                </div>
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>2019</strong></div>
                    <div>
                        <strong>Higher School Certificate</strong><br>
                        Syed Hatem Ali College, Barisal<br>
                        GPA: 5.0/5.0
                    </div>
                </div>
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>2017</strong></div>
                    <div>
                        <strong>Secondary School Certificate</strong><br>
                        Barisal Zilla School, Barisal<br>
                        GPA: 5.0/5.0
                    </div>
                </div>
            </ul>

            <!-- Research Interests -->
            <hr class="uk-margin-small">
            <p class="uk-h2 uk-text-bold" style="color:#BF5700;">Research Interests</p>
            <ul class="uk-list uk-list-bullet">
                <li>Generative AI</li>
                <li>Deep Learning</li>
                <li>Computer Vision</li>
                <li>Image Processing</li>
                <li>Explainable & Interpretable AI</li>
                <li>Real-time AI Systems</li>
                <li>Medical Imaging & AI for Health Care</li>
                <li>Multimodal Learning</li>
            </ul>

            <!-- Publications Section -->
            <hr class="uk-margin-small">
            <p id="research" class="uk-h2 uk-text-bold" style="color:#BF5700;">Publications (Conference)</p>
            <ul class="uk-list uk-margin-small-bottom">
                <li>
                    <div class="uk-text-lead"><a href="https://peccii.pust.ac.bd/" style="color:#b30749"><b>[IEEE PECCII 2026]</b></a> &nbsp; Parameter-Efficient Fine-Tuning with Adapters for Quantifying Sorghum Disease.</div>
                    <div> <b>Sabib Ahmed</b>, et al. </div>
                    <div><i>International Conference on Power, Electronics, Communications, Computing, and Intelligent Infrastructure 2026 (PECCII)</i></div>
                    <div><span style="background-color: #fbf719; color: white; padding: 2px 5px; border-radius: 5px;">Submitted</span></div>
                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Details
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            Designed a 
                            parameter-efficient adapter-based deep learning framework using EfficientNet-B3 for quantifying six 
                            classes of Sorghum diseases, achieving high accuracy while training only 15.56% of the model 
                            parameters. 
                        </div>
                    </details>
                    <div class="uk-text-lead"></div>
                </li>




                <li>
                    <div class="uk-text-lead"><a href="https://qpain.org/" style="color:#b30749"><b>[IEEE QPAIN 2026]</b></a> &nbsp; Evaluating Stable Diffusion with LoRA for Class-Imbalanced Medical Image Augmentation.</div>
                    <div> <b>Sabib Ahmed</b>, et al. </div>
                    <div><i>2026 IEEE 2nd International Conference on Quantum Photonics, Artificial Intelligence & Networking (QPAIN) </i></div>
                    <div><span style="background-color: #17a2b8; color: white; padding: 2px 5px; border-radius: 5px;">Under Review</span></div>
                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Details
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            Evaluated Stable Diffusion fine-tuned with Low-Rank Adaptation (LoRA) to generate minority-class renal stone 
                            CT images for class-imbalanced medical datasets. Demonstrated that moderate synthetic augmentation (25â€“50%) 
                            improves recall and F1-score across CNN and Transformer models while excessive synthetic reliance degrades performance. 
                        </div>
                    </details>
                    <div class="uk-text-lead"></div>
                </li>


                <li>
                    <div class="uk-text-lead"><a href="https://icecte.ruet.ac.bd/" style="color:#b30749"><b>[IEEE ICECTE 2026]</b></a> &nbsp; Dual-Stage Vision Transformer (DS-ViT) with Attention-Guided Patch Aggregation for Alzheimer's Disease Classification</div>
                    <div> <b>Sabib Ahmed</b> </div>
                    <div> <i>5th International Conference On Electrical, Computer, & Telecommunication Engineering (ICECTE) </i></div>
                    <div><span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Accepted</span></div>

                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Abstract
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            Alzheimer's disease (AD) is a progressive neurological illness that needs to be diagnosed early 
                            and accurately in order to be effectively treated. This study proposes a novel Dual-Stage Vision 
                            Transformer (DS-ViT) architecture that combines CNN-based local patch embedding with Transformer-based 
                            global attention to enable the model to capture both fine-grained structural information and 
                            inter-regional interdependence within brain MRI scans. An Alzheimer's MRI dataset with four stages 
                            of dementia was utilized to train and assess the proposed DS-ViT model. An early stopping strategy 
                            was used to reduce overfitting; as validation performance plateaued, training was stopped at the 
                            83rd epoch. According to experimental data, DS-ViT outperforms the standard ViT-Base/16 and 
                            traditional CNNs (VGG16, MobileNetV2, InceptionV3), achieving an accuracy of 95.40%. 
                            Additionally, the model regularly demonstrates strong and dependable classification performance across 
                            all classes with excellent precision, recall, and F1-scores. An important development in AI-driven 
                            diagnostic systems, the DS-ViT framework provides a flexible and modular design that may be applied to 
                            further medical imaging and neurodegenerative disease detection tasks.
                        </div>
                    </details>



                    <div class="uk-text-lead"></div>
                </li>

                <li>
                    <div class="uk-text-lead"><a href="https://eict2025.kuet.ac.bd/index.php" style="color:#b30749"><b>[IEEE EICT 2025]</b></a> &nbsp; Ensemble-ASNet: Weighted Transfer Learning Framework with Grad-CAM++ for Robust Kidney Stone Classification</div>
                    <div> <b>Sabib Ahmed</b> </div>
                    <div> <i>7th International Conference on Electrical Information and Communication Technology (EICT) </i></div>
                    <div><span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Accepted</span></div>
                    <div class="uk-text-lead"></div>

                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Abstract
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            Timely diagnosis and successful treatment depend on the accurate identification 
                            of renal abnormalities, including kidney stones, cysts, tumors, and normal tissue 
                            from CT scans, and automated, interpretable systems can aid in clinical decision-making 
                            while lowering diagnostic mistakes. In order to capitalize on the complementing 
                            characteristics of InceptionV3, VGG16, and MobileNetV2 in multi-scale, fine-grained, 
                            and effective feature extraction, this study suggests Ensemble-ASNet, a weighted ensemble 
                            framework. Grad-CAM++ visuals of the component models were used to evaluate interpretability, 
                            and class probabilities from the separate models are integrated using optimized ensemble weights. 
                            Ensemble-ASNet outperformed all individual baseline models, achieving 99.81% accuracy, precision, 
                            recall, and F1-score when tested on a kidney CT dataset. The models' emphasis on clinically significant
                            regions was validated by the visualizations, which increased their credibility. These findings show that
                            Ensemble-ASNet offers a very precise and comprehensible method for multi-class renal condition diagnosis, 
                            with great promise for clinical use and future expansion to temporal and multi-institutional imaging datasets.
                        </div>
                    </details>
                </li>

                <li>
                    <div class="uk-text-lead"><a href="https://icerie2025.sust.edu/" style="color:#b30749"><b>[ICERIE 2025]</b></a> &nbsp; An Innovative Approach to Smoker Status Prediction with ML Algorithms in Bangladesh</div>
                    <div> <b>Sabib Ahmed</b>, et al. </div>
                    <div><i>8th International Conference on Engineering Research, Innovation and Education (ICERIE 2025)</i></div>
                    <div><span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Accepted</span></div>
                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Abstract
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            In Bangladesh, smoking continues to be a significant issue for public health. As for the 
                            divisions in age, currently, about 18% of adults smoke, together with older and younger men, 
                            including 36.2% of men and 0.8%. Moreover, smoking, including both the use of non-combustible 
                            tobacco and different shades of age, particularly smokeless tobacco products, including betel quid 
                            and zarda, are significantly common among middle-aged to elderly men and women. Such an 
                            extensive consumption pattern leads to significant health complications, contributing to more than 
                            100,000 deaths in the country. About 7% of teenagers use smoking and tobacco products, hinting at 
                            negligence of youth tobacco use. In order to approximate and forecast smoking patterns, this study 
                            approaches the possibility and effectiveness of some machine learning algorithms for predicting the 
                            smoking status of patients based on their age, height, weight, waist circumference, visual acuity in 
                            both eyes, hearing capability in both ears, systolic and relaxation. We use seven machine learning 
                            algorithms: NaÃ¯ve Bayes, logistic regression classifier, random forest classifier, XGBoost classifier, 
                            Decision Tree , KNeighbors and a new approach called HEStacked to classify the smoking status of 
                            patients. Each algorithm is tested with different efficiency measures, such as accuracy, and confusion 
                            matrices, after being trained on a balanced dataset. Result illustrates the effectiveness of the 
                            HEStacked Classifier, which showed an impressive precision of around 88.03% in correctly 
                            classifying smoker status. This model highlights the important role of training and targeted 
                            intervention measures, which will be a great asset for public health activities aimed at the prevention 
                            and problem of diseases associated with smoking in more general. These findings can be used as a 
                            promising tool for the prediction of smoking status based on health risk perceptions of Bangladesh. 
                        </div>
                    </details>

                    <a href="https://www.researchgate.net/profile/Md-Osman-Goni-5/publication/399681314" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <div class="uk-text-lead"></div>
                </li>

                
            </ul>


            <!-- Publications Section -->
            <hr class="uk-margin-small">
            <p id="research" class="uk-h2 uk-text-bold" style="color:#BF5700;">Publications (Journal)</p>
            <ul class="uk-list uk-margin-small-bottom">

                <li>
                    <div class="uk-text-lead"><a href="https://link.springer.com/journal/11760" style="color:#b30749"><b>[Springer SIVP (Q2)]</b></a> &nbsp; Clinically Explainable Cross-Attention CNNâ€“ViT Framework for Automated Multi-Class Retinal Disease Screening Using OCT</div>
                    <div> <b>Sabib Ahmed</b>, et al. </div>
                    <div><i>Signal, Image and Video Processing, <b>Springer</b></i></div>
                    <div><b style="color:  #ff3333;">Schimago Ranking: Q2</b></div>
                    <div><span style="background-color: #17a2b8; color: white; padding: 2px 5px; border-radius: 5px;">Under Review</span></div>
                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Details
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            Developed a hybrid CNN-ViT model leveraging cross-attention mechanisms to improve multi-class retinal OCT 
                            image classification. Integrated dual explainability techniques like Grad-Cam and Attention Map to visualize 
                            both spatial and feature-level attention, enhancing interpretability. 
                            Achieved high accuracy across 8 retinal disease classes, demonstrating a 
                            robust and explainable approach for ophthalmic diagnostics. 
                        </div>
                    </details>
                    <div class="uk-text-lead"></div>
                </li>
            </ul>

            <!-- Thesis Section -->
            <hr class="uk-margin-small">
            <p id="thesis" class="uk-h2 uk-text-bold" style="color:#BF5700;">Undergraduate Thesis</p>
            <ul class="uk-list uk-margin-small-bottom">
                <li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>A Study on Real-Time Pavement Crack Detection Using YOLOv9: Challenges and Opportunities</b></span></div>
                    <div><b>Role:</b> Lead Researcher</div>
                    <!-- <div class="uk-margin-small-top">Developed a real-time pavement crack detection system using the YOLOv9 architecture. The work involved dataset preparation, custom training pipelines, model optimization, and evaluation for infrastructure monitoring applications. The thesis focused on improving detection accuracy, handling complex crack patterns, and enabling efficient real-time inference.</div> -->
                    <!-- <div class="uk-margin-small-top">
                        <span class="uk-label uk-margin-small-right">YOLOv9</span>
                        <span class="uk-label uk-margin-small-right">Real-time Detection</span>
                        <span class="uk-label uk-margin-small-right">Computer Vision</span>
                        <span class="uk-label uk-margin-small-right">Deep Learning</span>
                    </div> -->

                    <details style="margin-top: 10px;">
                        <summary style="cursor: pointer; font-weight: 600; color: #b30749;">
                            ðŸ“„ Abstract
                        </summary>

                        <div style="margin-top: 8px; line-height: 1.6; color: #444; text-align: justify;">
                            For efficient road maintenance and infrastructure safety, pavement crack detection is essential. 
                            Nevertheless, manual inspection techniques are time-consuming, prone to mistakes, and unsuitable 
                            for extensive monitoring. An automated crack detection system utilizing the cutting-edge deep learning 
                            model YOLOv9 is presented in this work. Four different types of cracks were identified in the 1,200 
                            annotated pavement images that made up the custom dataset: pothole, longitudinal, transverse, and alligator. 
                            Real-world variations in road conditions, surface textures, and lighting environments are captured in the dataset.
                            This dataset was used to train and assess YOLOv9, which produced an F1-score of 73.2% and a mean Average Precision (mAP)
                            of 70.4%. These outcomes reveal how well YOLOv9 performs in providing precise, scalable, and instantaneous crack detection. 
                            By facilitating prompt and well-informed decision-making by road authorities and civil engineers, the suggested system has 
                            the potential to greatly improve road safety and maintenance workflows. 
                        </div>
                    </details>




                </li>
            </ul>

            

            <!-- Applied ML Projects Section -->
            <hr class="uk-margin-small">
            <p id="projects" class="uk-h2 uk-text-bold" style="color:#BF5700;">Applied ML Projects</p>
            <ul class="uk-list uk-margin-small-bottom">
                <li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>Face Mask Detection</b></span></div>
                    <div class="uk-margin-small-top">Developed a YOLOv8-based object detection model capable of identifying three categories â€” mask, no mask, and bad mask â€” from both images and videos. The system can be used for real-time monitoring in public spaces.</div>
                    <div><b>Tools:</b> Python, PyTorch, OpenCV, Google Colab</div>
                </li>

                <li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>Brain Tumor Classification</b></span></div>
                    <div class="uk-margin-small-top">Designed a CNN model to classify brain tumors from CT and MRI images. Deployed as a Streamlit web app for real-time prediction and visualization.</div>
                    <div><b>Tools:</b> Python, TensorFlow, NumPy, Pandas, OpenCV, Streamlit</div>
                </li>

                <li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>Vehicle Detection</b></span></div>
                    <div class="uk-margin-small-top">Implemented a YOLOv12 model to detect 17 distinct vehicle types in images and videos. Suitable for traffic analysis, surveillance, and transportation monitoring.</div>
                    <div><b>Tools:</b> Python, PyTorch, OpenCV, Google Colab</div>
                </li>
            </ul>

            <!-- Technical Skills Section -->
            <hr class="uk-margin-small">
            <p id="skills" class="uk-h2 uk-text-bold" style="color:#BF5700;">Technical Skills</p>
            <ul class="uk-list uk-list-bullet">
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>Languages</strong></div>
                    <div>Python, C++, C, Java, JavaScript, HTML, CSS</div>
                </div>
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>ML & Deep Learning</strong></div>
                    <div>PyTorch, TensorFlow, Keras, Scikit-learn, CUDA, XGBoost</div>
                </div>
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>Computer Vision</strong></div>
                    <div>OpenCV, YOLO, CNN, Transformers, Roboflow</div>
                </div>
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>Data Science</strong></div>
                    <div>Pandas, NumPy, Matplotlib, Seaborn, MySQL</div>
                </div>
                <div class="uk-grid-small uk-child-width-expand@s" uk-grid>
                    <div class="uk-width-1-4@s"><strong>Tools</strong></div>
                    <div>VS Code, Jupyter Notebook, Anaconda, Git, GitHub, Linux (Ubuntu), LaTeX</div>
                </div>
            </ul>

            <!-- Contact Section -->
            <hr class="uk-margin-small">
            <p id="contact" class="uk-h2 uk-text-bold" style="color:#BF5700;">Contact</p>
            <div class="uk-child-width-1-2@m" uk-grid>
                <div class="uk-width-large">
                    <div class="uk-card uk-card-default uk-card-hover uk-card-body">
                        <h3 class="uk-card-title">Address</h3>
                        <p>
                            South Badda, Gulshan - 1 <br/>
                            Dhaka - 1212 <br/>
                            Bangladesh
                        </p>
                    </div>
                </div>
                <div class="uk-width-large">
                    <div class="uk-card uk-card-primary uk-card-hover uk-card-body" style="background-color: #BF5701">
                        <h3 class="uk-card-title">Email</h3>
                        <p>
                            <b>Primary</b> <br/>
                            sabibahmed40@gmail.com
                        </p>
                    </div>
                </div>
            </div>

            <!-- Social Links -->
            <div class="uk-margin-medium-top uk-text-center">
                <a href="mailto:sabibahmed40@gmail.com" class="social-icon" style="background-color: #EA4335;">
                    <i class="fas fa-envelope"></i>
                </a>
                <a href="https://scholar.google.com/citations?user=kb5sqbIAAAAJ&hl=en" class="social-icon" style="background-color: #4285F4;" target="_blank">
                    <i class="fas fa-graduation-cap"></i>
                </a>
                <a href="https://github.com/Ahmedsabib" class="social-icon" style="background-color: #333;" target="_blank">
                    <i class="fab fa-github"></i>
                </a>
                <a href="https://www.linkedin.com/in/sabib-ahmed-147471251/" class="social-icon" style="background-color: #0077B5;" target="_blank">
                    <i class="fab fa-linkedin-in"></i>
                </a>
            </div>

        </div>
        </div>

        <!-- Footer -->
        <div class="uk-section uk-flex uk-flex-center uk-section-secondary uk-height-small" style="background-color: #BF5701">
            <div class="uk-container uk-container-large uk-text-primary">
                <p class="uk-text-small uk-text-center">Copyright &copy; 2026 Sabib Ahmed. All Rights Reserved.</p>
            </div>
        </div>

    </body>
</html>


